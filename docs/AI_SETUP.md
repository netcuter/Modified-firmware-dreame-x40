# Konfiguracja AI dla Dreame X40 Assistant

Ten dokument opisuje szczeg√≥≈ÇowƒÖ konfiguracjƒô AI dla projektu.

## üéØ PrzeglƒÖd

Dreame X40 AI Assistant wspiera dwa typy modeli AI:

1. **Lokalny (LM Studio)** - Dzia≈Ça na Twoim komputerze, zero koszt√≥w, pe≈Çna prywatno≈õƒá
2. **Online (OpenAI/Claude/Gemini)** - W chmurze, wiƒôksza moc, wymaga API key

## üè† Model Lokalny - LM Studio

### Instalacja LM Studio

1. **Pobierz LM Studio:**
   - Strona: https://lmstudio.ai/
   - Wybierz wersjƒô dla swojego systemu (Windows/Mac/Linux)
   - Zainstaluj

2. **Uruchom LM Studio**

### Pobieranie modelu

1. W LM Studio kliknij **"Search"** (üîç)

2. Zalecane modele dla jƒôzyka polskiego:

   **Dla s≈Çabszych komputer√≥w (8GB RAM):**
   - `TheBloke/Mistral-7B-Instruct-v0.2-GGUF` (4-bit quantization)
   - Wielko≈õƒá: ~4GB
   - Szybko≈õƒá: Bardzo dobra
   - Jako≈õƒá PL: Dobra

   **Dla ≈õrednich komputer√≥w (16GB RAM):**
   - `TheBloke/Mistral-7B-Instruct-v0.2-GGUF` (5-bit quantization)
   - `TheBloke/OpenHermes-2.5-Mistral-7B-GGUF`
   - Wielko≈õƒá: ~5-6GB
   - Szybko≈õƒá: Dobra
   - Jako≈õƒá PL: Bardzo dobra

   **Dla mocnych komputer√≥w (32GB+ RAM):**
   - `TheBloke/Llama-2-13B-chat-GGUF`
   - `TheBloke/Nous-Hermes-2-Mixtral-8x7B-DPO-GGUF`
   - Wielko≈õƒá: 8-16GB
   - Szybko≈õƒá: ≈örednia
   - Jako≈õƒá PL: Wy≈õmienita

3. Kliknij **Download** przy wybranym modelu

4. Poczekaj na pobranie (mo≈ºe zajƒÖƒá chwilƒô)

### Uruchomienie serwera lokalnego

1. W LM Studio przejd≈∫ do zak≈Çadki **"Local Server"** (‚ö°)

2. Wybierz pobrany model z listy

3. Kliknij **"Start Server"**

4. Server uruchomi siƒô na porcie **1234** (domy≈õlnie)

5. Sprawd≈∫ czy dzia≈Ça:
   ```bash
   curl http://localhost:1234/v1/models
   ```

   Powiniene≈õ zobaczyƒá listƒô modeli.

### Konfiguracja w projekcie

1. Znajd≈∫ IP swojego komputera z LM Studio:

   **Windows:**
   ```cmd
   ipconfig
   ```
   Szukaj "IPv4 Address" (np. 192.168.1.50)

   **Linux/Mac:**
   ```bash
   ifconfig
   # lub
   ip addr
   ```

2. Edytuj `config/settings.yaml`:

   ```yaml
   ai:
     default_model: "local"

     local:
       enabled: true
       host: "192.168.1.50"  # TW√ìJ IP
       port: 1234
       model: "local-model"
       timeout: 30
       max_tokens: 2000
       temperature: 0.7
   ```

3. Zapisz i zrestartuj serwer backend

### Testowanie

```bash
# Uruchom backend
python src/main.py

# W logach powiniene≈õ zobaczyƒá:
# "Local AI client initialized and healthy"
```

## üåê Modele Online

### OpenAI (GPT-4, GPT-3.5)

1. **Uzyskaj API Key:**
   - Przejd≈∫ do: https://platform.openai.com/api-keys
   - Zaloguj siƒô lub za≈Ç√≥≈º konto
   - Kliknij **"Create new secret key"**
   - Skopiuj klucz (UWAGA: poka≈ºe siƒô tylko raz!)

2. **Konfiguracja:**

   ```yaml
   ai:
     online:
       default_provider: "openai"
       openai:
         enabled: true
         api_key: "sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"  # TW√ìJ KLUCZ
         model: "gpt-4"  # lub "gpt-3.5-turbo" (ta≈Ñszy)
         max_tokens: 2000
         temperature: 0.7
   ```

3. **Koszty (przybli≈ºone):**
   - GPT-3.5 Turbo: ~$0.002 za 1000 token√≥w (~500 s≈Ç√≥w)
   - GPT-4: ~$0.03 za 1000 token√≥w
   - GPT-4 Turbo: ~$0.01 za 1000 token√≥w

### Anthropic (Claude)

1. **Uzyskaj API Key:**
   - Przejd≈∫ do: https://console.anthropic.com/
   - Za≈Ç√≥≈º konto
   - Settings ‚Üí API Keys ‚Üí Create Key

2. **Konfiguracja:**

   ```yaml
   ai:
     online:
       default_provider: "anthropic"
       anthropic:
         enabled: true
         api_key: "sk-ant-xxxxxxxxxxxxxxxxxxxxx"  # TW√ìJ KLUCZ
         model: "claude-3-5-sonnet-20241022"
         max_tokens: 2000
         temperature: 0.7
   ```

3. **Modele:**
   - `claude-3-5-sonnet-20241022` - Najnowszy, najlepszy
   - `claude-3-haiku-20240307` - Szybszy, ta≈Ñszy
   - `claude-3-opus-20240229` - Najbardziej zaawansowany

### Google (Gemini)

1. **Uzyskaj API Key:**
   - Przejd≈∫ do: https://makersuite.google.com/app/apikey
   - Zaloguj siƒô kontem Google
   - Create API Key

2. **Konfiguracja:**

   ```yaml
   ai:
     online:
       default_provider: "google"
       google:
         enabled: true
         api_key: "AIzaSyxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"  # TW√ìJ KLUCZ
         model: "gemini-pro"
         max_tokens: 2000
         temperature: 0.7
   ```

## üîÑ Prze≈ÇƒÖczanie miƒôdzy modelami

### W web interface

1. Otw√≥rz interfejs: http://localhost:3000
2. W lewym panelu znajd≈∫ **"Model AI"**
3. Kliknij na wybrany model
4. Model zostanie prze≈ÇƒÖczony natychmiast

### Przez API

```bash
curl -X POST http://localhost:8000/api/v1/ai/switch-model \
  -H "Content-Type: application/json" \
  -d '{"model": "local"}'
```

Dostƒôpne opcje: `local`, `openai`, `anthropic`, `google`

### Auto-fallback

Je≈õli w≈ÇƒÖczone (`auto_fallback: true`), system automatycznie prze≈ÇƒÖczy siƒô na alternatywny model gdy g≈Ç√≥wny nie dzia≈Ça.

Przyk≈Çad:
- Pr√≥ba u≈ºycia modelu lokalnego
- Lokalny server nie odpowiada
- Automatyczne prze≈ÇƒÖczenie na OpenAI (je≈õli skonfigurowane)

## ‚öôÔ∏è Dostrajanie parametr√≥w

### Temperature (temperatura)

Kontroluje "kreatywno≈õƒá" modelu:

```yaml
temperature: 0.7  # Domy≈õlna
```

- **0.0 - 0.3:** Bardzo przewidywalne, sp√≥jne odpowiedzi
- **0.4 - 0.7:** Balans (ZALECANE dla robota)
- **0.8 - 1.0:** Bardzo kreatywne, r√≥≈ºnorodne (ryzykowne)

### Max Tokens

Maksymalna d≈Çugo≈õƒá odpowiedzi:

```yaml
max_tokens: 2000  # ~1500 s≈Ç√≥w
```

- **500-1000:** Kr√≥tkie odpowiedzi
- **1500-2000:** Standardowe (ZALECANE)
- **3000+:** Bardzo d≈Çugie (dro≈ºsze dla online)

### Timeout

Czas oczekiwania na odpowied≈∫ (sekundy):

```yaml
timeout: 30  # 30 sekund
```

- Lokalny model: 20-60s (zale≈ºy od sprzƒôtu)
- Online: 10-30s

## üß™ Testowanie konfiguracji

### Test lokalnego modelu

```bash
# Z LM Studio uruchomionym
curl -X POST http://localhost:1234/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "local-model",
    "messages": [{"role": "user", "content": "Cze≈õƒá!"}]
  }'
```

### Test przez Dreame Assistant API

```bash
curl -X POST http://localhost:8000/api/v1/chat \
  -H "Content-Type: application/json" \
  -d '{
    "message": "Jaki jest stan robota?",
    "include_context": true
  }'
```

## üêõ RozwiƒÖzywanie problem√≥w

### "Local AI client not responding"

1. Sprawd≈∫ czy LM Studio server dzia≈Ça
2. Sprawd≈∫ IP i port w konfiguracji
3. Sprawd≈∫ firewall (port 1234 musi byƒá otwarty)
4. Spr√≥buj: `curl http://[IP]:1234/v1/models`

### "OpenAI request failed"

1. Sprawd≈∫ API key (czy skopiowany poprawnie)
2. Sprawd≈∫ limity konta na OpenAI
3. Sprawd≈∫ po≈ÇƒÖczenie z internetem

### "Model responses are slow"

**Lokalny:**
- Spr√≥buj mniejszego modelu lub ni≈ºszej quantization
- Zamknij inne aplikacje
- U≈ºyj GPU je≈õli dostƒôpne (LM Studio ‚Üí Settings ‚Üí GPU)

**Online:**
- Sprawd≈∫ po≈ÇƒÖczenie internetowe
- Zmie≈Ñ region API (je≈õli dostƒôpne)

## üí° Porady

1. **Dla najlepszej prywatno≈õci:** U≈ºyj tylko modelu lokalnego
2. **Dla najlepszej jako≈õci:** Claude 3.5 Sonnet lub GPT-4
3. **Dla balansu:** Model lokalny jako domy≈õlny + OpenAI jako fallback
4. **Dla oszczƒôdno≈õci:** GPT-3.5 Turbo lub lokalny Mistral 7B

## üìä Por√≥wnanie modeli

| Model | Prywatno≈õƒá | Koszt | Jako≈õƒá PL | Szybko≈õƒá | Wymagania |
|-------|------------|-------|-----------|----------|-----------|
| Mistral 7B (local) | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | Darmowy | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | 8GB RAM |
| Llama 2 13B (local) | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | Darmowy | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | 16GB RAM |
| GPT-3.5 Turbo | ‚≠ê‚≠ê | $ | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | Internet |
| GPT-4 | ‚≠ê‚≠ê | $$$ | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | Internet |
| Claude 3.5 | ‚≠ê‚≠ê | $$ | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | Internet |
| Gemini Pro | ‚≠ê‚≠ê | $ | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | Internet |

## üîê Bezpiecze≈Ñstwo API Keys

**NIGDY** nie commituj kluczy API do git!

1. U≈ºyj pliku `.env`:
   ```bash
   cp .env.example .env
   nano .env
   ```

2. Dodaj klucze do `.env`:
   ```
   OPENAI_API_KEY=sk-...
   ANTHROPIC_API_KEY=sk-ant-...
   GOOGLE_API_KEY=AIza...
   ```

3. Plik `.env` jest w `.gitignore` - bezpieczny!

## üìö Dodatkowe zasoby

- **LM Studio:** https://lmstudio.ai/docs
- **OpenAI Docs:** https://platform.openai.com/docs
- **Anthropic Docs:** https://docs.anthropic.com/
- **Google AI:** https://ai.google.dev/
